{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_W4Z5-B5LsM",
        "outputId": "545fc7a1-0c03-4383-b4a7-08c18386524b"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2B8BoS2j3e1w"
      },
      "outputs": [],
      "source": [
        "def unpickle(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "\n",
        "def get_input(input_path):\n",
        "    n = 0\n",
        "    for file in os.listdir(input_path):\n",
        "        n += 1\n",
        "    Batch = [0 for _ in range(n)]\n",
        "\n",
        "    i = 0\n",
        "    for file in os.listdir(input_path):\n",
        "        Batch[i] = unpickle(input_path+\"/\"+file)\n",
        "        i +=1\n",
        "    output_vector = np.concatenate([Batch[i][b'labels'] for i in range(n)])\n",
        "    feature_vector = np.concatenate([Batch[i][b'data'] for i in range(n)])\n",
        "    return feature_vector,output_vector\n",
        "\n",
        "#feature_vector, output_vector = get_input(\"drive/MyDrive/COL341-A4/Train Set\")\n",
        "#feature_val, output_val = get_input(\"drive/MyDrive/COL341-A4/Validation Set\")\n",
        "feature_vector, output_vector = get_input(\"Train Set\")\n",
        "feature_val, output_val = get_input(\"Validation Set\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAR2tEySfUtb",
        "outputId": "d772d2ed-0e8c-4463-ad8c-a61f8eef5a88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(50000, 3072)\n",
            "<class 'numpy.ndarray'>\n",
            "[6 9 9 ... 9 1 1]\n",
            "0\n",
            "9\n",
            "(50000,)\n",
            "(10000, 3072)\n",
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "print(type(feature_vector))\n",
        "print(feature_vector.shape)\n",
        "\n",
        "print(type(output_vector))\n",
        "print(output_vector)\n",
        "print(min(output_vector))\n",
        "print(max(output_vector))\n",
        "#Labels from 0 to 9\n",
        "print(output_vector.shape)\n",
        "\n",
        "print(feature_val.shape)\n",
        "print(output_val.shape)\n",
        "#6000 Images per class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xJ-Jkfb9OWbV"
      },
      "outputs": [],
      "source": [
        "def relu(x):\n",
        "    return(x*(x>0))\n",
        "\n",
        "def relu_deriv(x):\n",
        "    deriv = (x>0).astype(int)\n",
        "    return deriv\n",
        "\n",
        "def CELoss(true, pred):\n",
        "    return abs(true-pred)\n",
        "\n",
        "def CELoss_deriv(true, pred):  #Check abs() #TODO\n",
        "    return 1 if int(true)!=int(pred) else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ajaNIsFDwaGc"
      },
      "outputs": [],
      "source": [
        "class Layer:\n",
        "    def __init__(self):\n",
        "        self.input = None\n",
        "        self.output = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QPosUMqdfUtc"
      },
      "outputs": [],
      "source": [
        "class Linear(Layer):\n",
        "    def __init__(self,input_size, output_size):\n",
        "        super().__init__()\n",
        "        self.weights = np.random.rand(input_size,output_size) - 0.5\n",
        "        self.bias = np.random.rand(1,output_size) - 0.5\n",
        "\n",
        "    def forward(self,input_vector):\n",
        "        self.input = input_vector.reshape(1,input_vector.size)\n",
        "        self.output = np.dot(self.input,self.weights) + self.bias\n",
        "        return self.output\n",
        "    \n",
        "    def backward(self, output_error, lr):\n",
        "        input_error = np.matmul(output_error, self.weights.T)\n",
        "        weights_error = np.matmul(self.input.T, output_error)\n",
        "\n",
        "        self.weights = self.weights - lr*weights_error\n",
        "        self.bias = self.bias - lr*output_error\n",
        "        return input_error\n",
        "\n",
        "class ReLU(Layer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        self.input = input_data\n",
        "        self.output = relu(self.input)\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, output_error, lr):\n",
        "        return relu_deriv(self.input) * output_error\n",
        "    \n",
        "class Flatten(Layer):   #TODO Verify\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    \n",
        "    def forward(self, input_data):\n",
        "        self.input = input_data\n",
        "        self.output = np.copy(input_data).reshape((1,input_data.size))\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, output_error, lr):\n",
        "        return output_error.reshape(self.input.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "00_2recYwaGg"
      },
      "outputs": [],
      "source": [
        "def convolve(input,weight,padding):\n",
        "    x = int((input.shape[0] - weight.shape[0] + 2 * padding) + 1)\n",
        "    y = int((input.shape[1] - weight.shape[1] + 2 * padding) + 1)\n",
        "    output = np.zeros((x,y))\n",
        "\n",
        "    padded_input = np.zeros((input.shape[0]+2*(padding),input.shape[1]+2*padding))\n",
        "    padded_input[padding:-1*padding,padding:-1*padding] = np.copy(input)\n",
        "\n",
        "    for col in range(padded_input.shape[1] - weight.shape[1]+1):\n",
        "        for row in range(padded_input.shape[0] - weight.shape[0]+1):\n",
        "            temp = weight * padded_input[row:row+weight.shape[0],col:col+weight.shape[1]]\n",
        "            output[row,col] = np.sum(temp)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yHyQYG4dwaGh"
      },
      "outputs": [],
      "source": [
        "class Conv2D(Layer):\n",
        "    def __init__(self,in_channels,out_channels,kernel_size):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "        self.weight_list = [0 for i in range(out_channels)]\n",
        "        for i in range(out_channels):\n",
        "            temp_list = [0 for j in range(in_channels)]\n",
        "            for j in range(in_channels):\n",
        "                weight = np.random.rand(kernel_size,kernel_size) -0.5\n",
        "                temp_list[j] = weight\n",
        "            self.weight_list[i] = temp_list\n",
        "        self.bias = np.random.rand(out_channels) - 0.5\n",
        "\n",
        "    def forward(self, input_data):  #Input as a 3D np array - 3 2Ds jaisa\n",
        "        temp_input = input_data[0]\n",
        "        self.input = input_data\n",
        "        self.output = np.zeros((self.out_channels,temp_input.shape[0],temp_input.shape[1]))\n",
        "\n",
        "        for i in range(self.out_channels):\n",
        "            for j in range(self.in_channels):\n",
        "                input = input_data[j]\n",
        "                weight = self.weight_list[i][j]\n",
        "                self.output[i,:,:] = self.output[i,:,:] + convolve(input,weight,padding = (weight.shape[0]-1)//2)\n",
        "            self.output[i,:,:] = self.output[i,:,:] #+ self.bias[i]\n",
        "        return self.output\n",
        "    \n",
        "    def backward(self,output_error,lr):\n",
        "        #Update Bias check\n",
        "        #Pass error to prev layer\n",
        "\n",
        "        weights_error = np.zeros_like(self.weight_list)\n",
        "\n",
        "        for i in range(self.out_channels):#Output_error for each output_channel\n",
        "            op_error = output_error[i]\n",
        "            for j in range(self.in_channels):\n",
        "                input = self.input[j]\n",
        "                error = convolve(input,op_error,(self.kernel_size-1)//2)\n",
        "                weights_error[i,j] = error\n",
        "        #W Updated\n",
        "\n",
        "        input_error = np.zeros_like(self.input,dtype=float)\n",
        "        for j in range(self.in_channels):\n",
        "            error = input_error[j]\n",
        "            for i in range(self.out_channels):\n",
        "                op_error = output_error[i]\n",
        "                weight = self.weight_list[i][j]\n",
        "                weight180 = np.flipud(weight)\n",
        "                error += convolve(op_error,weight180,(weight180.shape[0]-1)//2)\n",
        "\n",
        "        for i in range(self.out_channels):\n",
        "            for j in range(self.in_channels):\n",
        "                self.weight_list[i][j] -= lr*weights_error[i,j]\n",
        "        return input_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wX02xLXrwaGj"
      },
      "outputs": [],
      "source": [
        "class MaxPool2D(Layer):\n",
        "    def __init__(self,kernel_size):\n",
        "        super().__init__()\n",
        "        self.kernel_size = kernel_size #Assuming stride is kernel_size\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        d1 = int((input_data.shape[1])/self.kernel_size)\n",
        "        d2 = int((input_data.shape[2])/self.kernel_size)\n",
        "        self.output = np.zeros((input_data.shape[0],d1,d2))\n",
        "        for i in range(input_data.shape[0]):\n",
        "            op = np.zeros((d1,d2))\n",
        "            ip = input_data[i]\n",
        "            for a in range(d1):\n",
        "                for b in range(d2):\n",
        "                    op[a,b] = np.amax(ip[a*self.kernel_size:(a+1)*self.kernel_size,b*self.kernel_size:(b+1)*self.kernel_size])\n",
        "            self.output[i] = op\n",
        "        self.input = input_data\n",
        "        return self.output\n",
        "    \n",
        "    def backward(self,output_error,lr):\n",
        "        input_data = self.input\n",
        "        d1 = int((input_data.shape[1])/self.kernel_size)\n",
        "        d2 = int((input_data.shape[2])/self.kernel_size)\n",
        "        \n",
        "        input_error = np.zeros_like(self.input)\n",
        "\n",
        "        for i in range(input_data.shape[0]):\n",
        "            ip = input_data[i]\n",
        "            for a in range(d1):\n",
        "                for b in range(d2):\n",
        "                    m = ip[a*self.kernel_size:(a+1)*self.kernel_size,b*self.kernel_size:(b+1)*self.kernel_size]\n",
        "                    rel_posn = np.unravel_index(np.argmax(m, axis=None), m.shape)\n",
        "                    posn = [a*self.kernel_size,b*self.kernel_size]\n",
        "                    posn[0] += rel_posn[0]\n",
        "                    posn[1] += rel_posn[1]\n",
        "                    input_error[i,posn[0],posn[1]] = lr*output_error[i,a,b]\n",
        "        return input_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4ptLLvIEOMkV"
      },
      "outputs": [],
      "source": [
        "class Network:\n",
        "    def __init__(self,layers,loss,loss_deriv):\n",
        "        self.layers = layers\n",
        "        self.loss = loss\n",
        "        self.loss_deriv = loss_deriv\n",
        "\n",
        "    def predict(self, input_data):\n",
        "      #Change code of this function whole\n",
        "      samples,_ = input_data.shape\n",
        "      result = []\n",
        "      for i in range(samples):\n",
        "          output = input_data[i]\n",
        "          for layer in self.layers:\n",
        "              output = layer.forward(output)\n",
        "          result.append(output)\n",
        "      return result\n",
        "\n",
        "    def fit(self, x_train, y_train, n_epochs, lr, batch_size):\n",
        "        n = len(y_train)\n",
        "\n",
        "        for i in range(n_epochs):\n",
        "          epoch_loss = 0\n",
        "          for j in range(n):\n",
        "              output = np.copy(x_train[j])\n",
        "              for l in self.layers:\n",
        "                output = l.forward(output)\n",
        "\n",
        "              op = np.argmax(output)\n",
        "              epoch_loss += self.loss(y_train[j],op)\n",
        "              dev = self.loss_deriv(y_train[j],op)\n",
        "\n",
        "              if(j%batch_size==0):\n",
        "                error_dev = dev*(output)/np.linalg.norm(output)\n",
        "                continue\n",
        "              elif(j%batch_size==31):\n",
        "                 error_dev += dev*(output)/np.linalg.norm(output)\n",
        "                 error_dev = error_dev/batch_size\n",
        "                 #print(\"Back at \",j)\n",
        "              else:\n",
        "                error_dev += dev*(output)/np.linalg.norm(output)\n",
        "                continue\n",
        "              for l in reversed(self.layers):\n",
        "                error_dev = l.backward(error_dev, lr)\n",
        "          mean_loss = epoch_loss/n\n",
        "          print(\"Epoch :\",i+1,\" and Error :\",mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2Eox-m3mNpku"
      },
      "outputs": [],
      "source": [
        "layers = [\n",
        "    Conv2D(3,32,3),\n",
        "    ReLU(),\n",
        "    MaxPool2D(2),\n",
        "    Conv2D(32,64,5),\n",
        "    ReLU(),\n",
        "    MaxPool2D(2),\n",
        "    Conv2D(64,64,3),\n",
        "    ReLU(),\n",
        "    Flatten(),\n",
        "    Linear(64*8*8, 64),\n",
        "    ReLU(),\n",
        "    Linear(64, 10)\n",
        "]\n",
        "net = Network(\n",
        "    layers = layers,\n",
        "    loss = CELoss,\n",
        "    loss_deriv = CELoss_deriv\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "y3oc8T7BPJfh",
        "outputId": "379bf266-7bd4-4c7f-a866-ec170b8fa53d"
      },
      "outputs": [],
      "source": [
        "feature_reshaped = feature_vector.reshape((50000,3,32,32))\n",
        "net.fit(feature_reshaped,output_vector,20,0.001,32)#20 epochs\n",
        "\n",
        "predicted_vector = net.predict(feature_reshaped)\n",
        "print(predicted_vector)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
